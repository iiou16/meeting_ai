# 会議議事録自動作成アプリ 仕様書

## 1. プロダクト概要

- **目的**: 会議動画から自動的に議事録を生成し、参加者が重要ポイントとアクションアイテムをすばやく把握できるようにする。
- **想定ユーザー**: 社内で定期的にオンライン会議を行うチーム、録画を共有する必要があるプロジェクトマネージャー。
- **提供価値**: 非参加者でも短時間で内容を理解できる要約と、タイムスタンプ付きで原文にアクセスできる精度の高い文字起こし。

## 2. 処理フロー

1. フロントエンドが動画ファイル(MP4/Mov/WebM等)または動画URLを受け取り、バックエンドAPIへ送信。
2. Pythonバックエンドが動画から音声トラックを抽出し、必要に応じてPCM/WAVなどに変換。
3. ワーカー処理でOpenAI GPT-4o Transcribe APIを利用し、音声→テキスト変換を実施。
4. 文字起こし結果を整形し、セクション分割や話者推定（可能であれば）を実施。
5. 文字起こしをもとに、タイムスタンプ付きの要約・アクションアイテムを生成（GPT-4o等のLLMを活用）。
6. バックエンドが生成結果を永続化し、フロントエンドは文字起こし全文、ハイライト、要約、アクションアイテムをUIおよびエクスポート機能で提供。

## 3. 機能要件

- **動画入力**
  - ローカルファイルアップロード（最大長さ・サイズ制限を設定）。
  - URLインポート（クラウドストレージや会議録画リンク）。ダウンロード処理は非同期。
- **音声抽出・前処理**
  - FFmpeg等で動画から音声のみ抽出。
  - 長時間動画に対応するための分割（例: 15分単位）とサンプリングレート変換。
- **文字起こし**
  - OpenAI GPT-4o Transcribeを利用。
  - 言語自動検出 + ユーザー指定言語をサポート。
  - 長時間動画向けにチャンクごとのAPI呼び出しとマージ。
  - 文字起こし結果にタイムスタンプ情報を保持。
- **要約生成**
  - タイムスタンプ付きの段落要約（セクションごと）。
  - 全体サマリー（概要、決定事項、TODO）。
  - オプション: 話者ごとの発言集計とキーワード抽出。
- **結果出力**
  - UI: Webダッシュボードで閲覧（フィルタリング、検索）。
  - エクスポート: JSON/Markdown/CSV(アクションアイテム)。
  - API: REST/GraphQLで取得可能なエンドポイントを用意。
- **ジョブ管理**
  - 非同期処理キューに投入し、進捗をポーリングまたはWebSocketで通知。
  - 失敗時の再試行・エラー通知。

## 4. 非機能要件

- **パフォーマンス**: 1時間の録画を10分以内で処理することを目標（ハードはクラウド構成に依存）。
- **信頼性**: 再試行メカニズムと途中経過の永続化で中断時の再開を可能にする。
- **セキュリティ**: アップロード動画は暗号化ストレージに保存、APIキーやアクセストークンを安全に管理。
- **プライバシー**: 保存期間と削除方針を明確化。ユーザーがいつでもデータ削除要求が可能。
- **スケーラビリティ**: ワーカーの水平スケールに対応したクラウド構成（例: AWS Lambda + SQS、またはコンテナ化）。

## 5. 技術スタック (想定)

- **フロントエンド**: Next.js / React、TypeScript、Tailwind CSS（別リポジトリorフロント専用フォルダで管理）。
- **バックエンド**: Python FastAPI（uvで仮想環境と依存関係を管理）。
- **バッチ処理**: Pythonワーカー（RQ/Celery/Arq等） + Redisキュー。バックエンドと同じuvベース環境で管理。
- **音声処理**: FFmpeg（Pythonバインディング: ffmpeg-python など）。
- **外部API**: OpenAI GPT-4o Transcribe、要約用にOpenAI GPT-4oまたは4.1。
- **データストア**: PostgreSQL (議事録メタデータ)、Object Storage (動画/音声ファイル)、Redis (ジョブキュー管理)。
- **インフラ**: Dockerコンテナ、CI/CD（GitHub Actions等）。

## 6. API設計 (概要)

- `POST /api/videos`: 動画アップロード。レスポンスに処理ジョブID。
- `GET /api/jobs/{id}`: ジョブの進捗・ステータス取得。
- `GET /api/meetings/{id}`: 文字起こし全文／要約／アクションアイテムを返却。
- `POST /api/meetings/{id}/export`: 形式指定でエクスポート生成。
- `DELETE /api/meetings/{id}`: データ削除リクエスト。
- フロントエンドは上記APIをBFF的に利用し、データ取得専用の型定義を共有ライブラリで管理。

## 7. データモデル (例)

- **Meeting**
  - `id`, `title`, `recorded_at`, `duration`, `status`, `created_by`
- **MediaAsset**
  - `id`, `meeting_id`, `type (video|audio)`, `path`, `duration`, `sampling_rate`
- **TranscriptSegment**
  - `id`, `meeting_id`, `start_ms`, `end_ms`, `speaker_label`, `text`
- **SummaryItem**
  - `id`, `meeting_id`, `segment_start_ms`, `segment_end_ms`, `summary_text`, `priority`
- **ActionItem**
  - `id`, `meeting_id`, `owner`, `due_date`, `description`

## 8. エラーハンドリング

- 入力ファイルのフォーマット不正、API失敗、音声抽出失敗時の詳細ログ。
- 再試行回数の上限とユーザー通知（メール／UI）。
- APIキーの失効や利用制限到達時の対応（ユーザーへのリトライ依頼）。

## 9. セキュリティ・コンプライアンス

- アクセス制御: OAuth 2.0/OIDCでログイン、RBACによる閲覧権限の制御。
- ログ監査: 操作ログを保存し、監査証跡を確保。
- 個人情報保護: 匿名化オプションやデータ削除APIの提供。

## 10. マイルストーン

1. POC: 単一動画アップロード → 音声抽出 → GPT-4o Transcribe → 要約生成までの一連のバッチ処理をCLIで確認。
2. Alpha: Webフロントからのアップロードと結果閲覧、基本的なジョブ管理を実装。
3. Beta: ユーザー管理、多言語対応、アクションアイテム抽出、自動エクスポート機能を追加。
4. GA: スケーリング、監査ログ、通知機能を整備し、運用フローを確立。

## 11. 未確定事項・オープンクエスチョン

- 動画ファイルの想定保存期間と保管場所（自社/クラウド）。
- 要約の粒度（5分単位／話者単位など）とフォーマット要件。
- 話者識別をOpenAIのみで行うか、別モデルを併用するか。
- 認証・課金モデル（社内利用のみか、外部提供か）。

## 12. プロジェクト構成（現状）

- `Docs/`: 仕様書、TODO、開発手順などのドキュメント。
- `backend/`: FastAPI + uv 管理のバックエンド。`src/meetingai_backend` 以下にアプリケーションコード、`tests/` にPytestテストを配置。
- `frontend/`: Next.js (App Router) ベースのフロントエンド。Jest + Testing Library でユニットテストを実施。
- プロジェクト直下に `.env` を配置し、APIキー等の環境変数を管理。
